# RAG-With-Unsloth-s-Dynamic-4--bit-Quantization
# ğŸ” Retrieval-Augmented Generation (RAG) using Unsloth 4-bit Quantized Models

This project implements a **Retrieval-Augmented Generation (RAG)** pipeline using **Unslothâ€™s dynamic 4-bit quantized models**, ideal for running on low VRAM environments like Google Colab.

ğŸ“„ The pipeline loads a custom PDF, splits it into chunks, embeds and indexes them with FAISS, and answers user questions based on **retrieved relevant context**.

---

## ğŸš€ Features

- ğŸ”— **Unsloth LLaMA 3 4-bit** model for low-memory inference.
- ğŸ“„ **PDF document ingestion** and chunking.
- ğŸ§  **HuggingFace sentence embeddings** for semantic search.
- ğŸ“š **FAISS vectorstore** for fast similarity retrieval.
- ğŸ” **LangChain RAG pipeline** with custom prompts.
- âš¡ï¸ Optimized for **Colab or low-VRAM GPUs** using 4-bit dynamic quantization.

---

## ğŸ“ Project Structure

